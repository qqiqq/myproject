设置字符串键值
set foo bar

查询字符串
get foo

设置多个字符串键值
mset a 1 b 2 c 3 d 4

查询多个字符串
mget a b c d

设置字符串时，对应键不存在，否则设置失败，
setnx hello world
可用于分布式事务锁：https://redis.io/topics/distlock


计数
incr counter

自增还有以下函数
decr key 自减
incrby key increment 自增指定值
decrby key decrement 自减指定值
incrbyfloat key increment 自增指定浮点值

键值后追加
APPEND hello ' and beijing'

键值字符串长度
STRLEN hello

设置字符串键值，并返回被覆盖的原值
getset hello world

设置字符串键值，从指定位置（0）开始，替换成指定值（lol）
SETRANGE hello 0 lol

从指定位置范围内获取字符串键值
GETRANGE hello 1 3

hash结构
适用于存储关系型数据
设置哈希值，user:1键的name域（field）的值为tom
hset user:1 name tom

查询哈希值，user:1键的name域的值
hget user:1 name

删除哈希
HDEL user:1 age

计算哈希下的field数量
HLEN user:1

查询哈希下多个field的值
hmget user:1 name age

设置哈希下多个field的值
hmset user:2 name mike age 12 city tianjin

查询指定键下所有field名字
hkeys user:2

查询指定键下所有field的值
hvals user:2

查询指定键下所有field-value对
HGETALL user:2

判断指定field是否存在
HEXISTS user:2 name

指定键的field的值递增指定值
HINCRBY user:2 age 1

指定键的field的值字节长度
HSTRLEN user:2 name


list操作
从右端向list中插入数据
rpush listkey c b a
从左端插入
lpush listkey c b a

从左端根据指定范围查询list，-1为最后一个index
lrange listkey 0 -1

在元素a前插入元素x
LINSERT listkey before a x
在元素4后插入元素10
linsert listkey after 4 10

查询指定位置的元素值
lindex listkey -1

查看list的长度（元素数量）
llen listkey

从list左端弹出数据
lpop listkey
从右端弹出
rpop listkey

从左端开始，删除3个元素a
LREM listkey 3 a
从右端开始，删除2个元素a
LREM listkey -2 a
删除所有元素5
lrem listkey 0 5

保留指定范围的数据
LTRIM listkey 0 -3

修改指定元素的值
lset listkey 3 xxx

从指定的list中pop元素，可以设置timeout（0）
brpop list1 list 2 list3 0
timeout为0时一直等待队列中填充数据（若队列为空）
一旦指定队列中有数据，将会在第一个发起brpop的会话中反馈元素

以下是适用list的应用场景
lpush+lpop=Stack（栈）
lpush+rpop=Queue（队列）
lpsh+ltrim=Capped Collection（有限集合）
lpush+brpop=Message Queue（消息队列）


集合操作：
添加集合元素
sadd myset a b c

删除元素
srem myset a b

计算集合内元素数量（时间复杂度为O（1））
scard myset

集合内是否存在元素c
SISMEMBER myset c

随机返回指定数量的集合内元素，不指定数量，默认为1
SRANDMEMBER myset 3

随机弹出指定数量的集合内元素，不指定数量，默认为1
spop myset 2

遍历集合内元素
SMEMBERS myset

集合间操作
注意：redis集群版对多key命令的支持，只能支持多key都在同一个slot上，即使多个slot在同一个节点上也不行

多个集合的交集
sinter user:1:follow user:2:follow

多个集合的并集
sunion user:1:follow user:2:follow

多个集合的差集
sdiff user:1:follow user:2:follow

将多个集合的计算结果存入user:1_2:inter集合中
sinterstore/suionstore/sdiffstore user:1_2:inter user:1:follow user:2:follow

以下是适用集合的应用场景
sadd=Tagging（标签）
spop/srandmember=Random item（生成随机数，比如抽奖）
sadd+sinter=Social Graph（社交需求）


有序集合
添加成员，时间复杂度为O（log（n））
zadd user:ranking 1 kris 91 mike 200 frank 220 tim 250 martin

计算成员个数
zcard user:ranking

查询某个成员的分数，如果成员不存在则返回nil
ZSCORE user:ranking mike

计算成员排名
从高到低排（从0开始）
zrevrank user:ranking mike
从低到高排（从0开始）
zrank user:ranking tim

删除成员
ZREM user:ranking tim

增加成员分数
ZINCRBY user:ranking 9 kris

返回指定范围的成员，并返回分数（可选）
从高到低排（从0开始）
ZREVRANGE user:ranking 2 4 withscores
从低到高排（从0开始）
zrange user:ranking 0 3 withscores
返回所有成员
zrange user:ranking 0 -1 withscores

返回指定分数的成员，并返回分数（可选）
ZRANGEBYSCORE user:ranking 50 220 withscores
zrevrangebyscore user:ranking 221 200 withscores
200以上的成员（无限大）
ZRANGEBYSCORE user:ranking 200 +inf withscores

返回指定分数内的成员数量
zcount user:ranking 100 200

删除指定排名内的成员
ZREMRANGEBYRANK user:ranking 0 1
类似
删除指定分数内的成员
zremrangebyscore user:ranking 250 +inf

集合间操作
交集
使用默认参数，集合成员做交集，分数相加
zinterstore user:ranking:1_inter_2 2 user:ranking:1 user:ranking:2
集合成员做交集，分数取交集成员的分数乘以权重后的较大值
zinterstore user:ranking:1_inter_2 2 user:ranking:1 user:ranking:2 weights 1 0.5 aggregate max

并集
类似交集，参数作用与交集一致
zunionstore user:ranking:1_union_2 2 user:ranking:1 user:ranking:2


使用场景：
排行榜系统




单键管理
删除指定键
del hello [key]

重命名键，可以对集合、hash等键重命名
rename zsetkey zsetky
rename user:1 user:info:1
当重命名的键不存在时，重命名才能成功，避免覆盖
renamenx zsetkey zsetky

返回当前库中的键值对数量
dbsize

随机返回一个键
randomkey

键过期
EXPIRE hello 10
查询键的剩余时间
ttl hello
毫秒级过期时间
pexpire key milliseconds
清除键的过期时间，即保留键
PERSIST key
以下命令相当于set+expire
setex name 50 vagrant
注意，字符串键在执行过set后，会移除过期时间

键迁移
将键在数据库间迁移
move key db

实例间迁移
从源库执行以下命令，ip和port为目标地址
migrate host port key|"" destination-db timeout [copy] [replace] [KEYS key [key
例如：
MIGRATE 192.168.221.134 10003 "" 0 5000 COPY KEYS key1 key2 key3


遍历键
全量遍历键
keys *
keys [j,r]edis

增量遍历键
scan cursor [MATCH pattern] [COUNT count]
例如：
scan 0 match key* count 3

zscan key cursor [MATCH pattern] [COUNT count]
例如：
ZSCAN user:ranking:1_union_2 0 match *m* count 2
以上命令均返回两部分结果
part1，当前游标位置，为0说明迭代结束，否则下次执行时scan时，从这个值开始
part2，实际查询得到的结果

除了zscan还有以下类似命令：
hscan、sscan

最后scan命令族不能保证事务的一致性，存在脏读等现象


数据库管理
数据库切换
select 3

清除当前数据库内容/内容清除所有数据库下的所有
flushdb/flushall


redis重要功能
慢查询：
设置慢查询的阈值，单位微秒（1秒=1000毫秒=1000000微秒）
config set slowlog-log-slower-than 20000
设置内存中保留慢查询的记录数
config set slowlog-max-len 1000

持久化配置
config rewrite

查询配置
CONFIG GET slowlog*

获取慢查询日志
SLOWLOG get 3
其中的数字为返回的条数

当前慢查询列表中总的记录条数
slowlog len

慢查询日志列表清理
slowlog reset

慢查询的最佳实践：
config set slowlog-log-slower-than 1000
config set slowlog-max-len 1000
建议设置慢查询的阈值为1毫秒，确保单线程的redis高峰响应时间高于1000qps
日志保留超过1000条，超出部分建议通过slowlog get转储到其他数据储存上，例如mysql

慢查询只记录命令执行时间，不含单线程下，命令排队等候执行的时间


redis shell相关命令：
redis-cli:
-p为连接的端口，-r为命令重复执行次数，-i为每次间隔时间（秒）
redis-cli -p 10000 -r 3 -i 1 info Memory|grep used_memory_human

-x类似shell命令中的管道占位符，用于给redis传递命令参数
echo "world" | redis-cli -x set hello

-c命令用于在cluster环境下，客户端访问的实例不包含相关slot时，自动转移到对应实例

--bigkeys通过scan命令，用于查找redis中较大的key，形成相关报告
redis-cli -p 10000 --bigkeys

--stat类似于top，不如info信息全面
redis-cli -p 10000 --stat
能够实时反馈redis中的以下内容：
------- data ------ --------------------- load -------------------- - child -
keys       mem      clients blocked requests            connections          
12         1.80M    2       0       2649 (+0)           13          
12         1.80M    2       0       2650 (+1)           13          

--raw和--no-raw参见以下例子：
redis-cli -p 10000 set shanghai "上海"

redis-cli -p 10000 get shanghai
"\xe4\xb8\x8a\xe6\xb5\xb7"

redis-cli -p 10000 --raw get shanghai 
上海


redis-server:

redis-benchmark为Redis做基准性能测试

-c 客户端并发数
-n 客户端请求总量
redis-benchmark -c 50 -n 1000

-q仅显示redis-benchmark中所有访问类型的requests per second信息
redis-benchmark -h smp -p 30001 -c 100 -n 10000 -q

-r 选项会在key、counter键上加一个12位的后缀，
-r 10000代表只对后四位做随机处理，并非随机数
redis-benchmark -h smp -p 30001 -c 100 -n 20000 -r 10000

-t 选项可以对指定命令进行基准测试。
redis-benchmark -h smp -p 30001 -c 100 -n 20000 -t get,set -q

--csv选项会将结果按照csv格式输出，便于后续处理

redis事务：

multi 启动事务
exec 执行并结束事务
两条命令之间的所有命令将被queued在内存中

discard 终止事务

说明几点关于事务的情况：
1、事务中出现单个（或多个）语法错误：
造成整个事务无法执行，即所有数据保持不变
2、事务执行时错误：
例如对于不同类型的数据使用错误的命令，但语法正确
会造成错误命令的执行失败，其他命令执行成功
这里redis不支持回滚

watch 用于在事务开始前监视事务相关的对象
若事务期间，监视对象被修改，则整个事务失败，无法修改任何数据

Bitmaps
关于redis中bitmaps数据结构，其实是用字符串的形式实现位图格式

setbit
设置指定键的偏移量（offset）的值
setbit unique:users:2016-04-05 0 1
setbit unique:users:2016-04-05 5 1
此时unique:users:2016-04-05键的1~4偏移量上的值均为0，且5后的值亦为0

getbit
获取键的第offset位的值（从0开始算）
getbit unique:users:2016-04-05 40

bitcount
获取键在指定范围内值为1的个数（默认为从0开始到最后一个1的位置）
bitcount unique:users:2016-04-05 1 3

bitop
对于多个bitmaps键做集合操作
bitop op destkey key [key....]
例如：
bitop or unique:users:2016-04-04_05 unique:users:2016-04-04 unique:users:2016-04-05
对unique:users:2016-04-04和unique:users:2016-04-05做或操作
结果存入unique:users:2016-04-04_05
特别注意，cluster环境下不允许此类操作

获取指定范围的第一个target Bit的偏移量
bitpos unique:users:2016-04-04 1 2 40
bitpos unique:users:2016-04-04 0 11 20

bitmaps的适用场景：
存储大量简单格式的信息，能用0/1表示的二元属性数据
例如网站日活用户统计等


hyperloglog
一种使用较少内存空间存储大量数据的格式，确切的说是一种算法
通过概率算法实现的一种数据存储
pfadd
向键中添加值
pfadd 2016_03_05:unique:ids "uuid-4" "uuid-5" "uuid-6" "uuid-7"

pfcount
计算键中值得数量
PFCOUNT 2016_05_01:unique:ids 

pfmerge
可以求出多个HyperLogLog的并集并赋值给destkey
pfmerge 2016_03_05_06:unique:ids 2016_03_05:unique:ids 2016_03_06:unique:ids

HyperLogLog内存占用量非常小，但是存在错误率，因此适用以下场景：
只为了计算独立总数，不需要获取单条数据。
可以容忍一定误差率，毕竟HyperLogLog在内存的占用量上有很大的优势。


消息队列：
订阅消息，向channel:sport订阅消息
SUBSCRIBE channel:sport
无法查收到订阅操作之前的命令

发布消息，向channel:sport发布消息
publish channel:sport "Time win the championship"

取消订阅
UNSUBSCRIBE channel:sport

按模式订阅消息
psubscribe it*
支持glob风格的订阅命令
包括取消订阅消息
unpsubscribe it*

查询订阅数超过1的活跃频道
PUBSUB channels
pubsub channels channel:*r*
注意这里的订阅数量不含psubscribe订阅的量

查询指定频道的订阅数量
pubsub numsub channel:sports
注意，这里不能使用通配符等glob格式

查询使用模式匹配方式订阅频道的数量
pubsub numpat

关于redis的发布订阅功能，相对于kafka等消息框架，功能较为简单、粗糙，极端环境下的性能可能也不行，
优点在于其结构简单，功能易学易用，门槛较低

GEO
添加GEO信息
geoadd key longitude latitude member 
例如：
GEOADD cities:location 116.28 39.55  beijing
坐标为116.28 39.55，分别为经度和纬度
geoadd cities:locations 117.12 39.08 tianjin 114.29 38.02 shijiazhuang 118.01 39.38 tangshan 115.29 38.51 baoding
同时添加多个member

更改GEO信息
geoadd key longitude latitude member 
反馈为0，但是相关信息会更新

查询指定member的GEO信息
GEOPOS cities:locations baoding

计算指定key中两个member的距离
geodist cities:locations baoding tianjin km
Km可以指定其他参数，如m米，mi英里，ft英尺

根据给定的坐标地址（116.403878 39.914942），计算集合中member最远（desc）的成员，并显示距离，单位km
georadius cities:locations 116.403878 39.914942 10 km withdist desc

查找指定GEO的member，在指定距离范围内的member，单位km
georadiusbymember subways qianmen 10 km

删除GEO的member
zrem key member
由于geo未提供相关接口，可以使用zset底层命令实现


redis客户端：
jedis for java:
Jedis 基本功能：
package Test;
import redis.clients.jedis.*;

public class testForJedis {
	public static void main(String[] args) {
		Jedis jedis = new Jedis("192.168.146.11",6379);
		jedis.select(2);
		jedis.set("hello","world");
		String value = jedis.get("hello");
		System.out.println(value);
		jedis.close();
	}

}

Jedis基本API：
// 1.string
// 输出结果： OK
jedis.set("hello", "world");
// 输出结果： world
jedis.get("hello");
// 输出结果： 1
jedis.incr("counter");
// 2.hash
jedis.hset("myhash", "f1", "v1");
jedis.hset("myhash", "f2", "v2");
// 输出结果： {f1=v1, f2=v2}
jedis.hgetAll("myhash");
// 3.list
jedis.rpush("mylist", "1");
jedis.rpush("mylist", "2");
jedis.rpush("mylist", "3");
// 输出结果： [1, 2, 3]
jedis.lrange("mylist", 0, -1);
// 4.set
jedis.sadd("myset", "a");
jedis.sadd("myset", "b");
jedis.sadd("myset", "a");
// 输出结果： [b, a]
jedis.smembers("myset");
// 5.zset
jedis.zadd("myzset", 99, "tom");
jedis.zadd("myzset", 66, "peter");
jedis.zadd("myzset", 33, "james");
// 输出结果： [[["james"],33.0], [["peter"],66.0], [["tom"],99.0]]
jedis.zrangeWithScores("myzset", 0, -1);

关于Jedis的序列化/反序列化：

关于Jedis连接池的使用：
package Test;
import org.apache.commons.pool2.impl.*;

import redis.clients.jedis.*;

public class testForJedisPool {
	public static void main(String[] args) {
	Jedis jedis = null;
	GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig();
	JedisPool jedisPool = new JedisPool(poolConfig, "192.168.146.12", 6379);
	try {
		jedis = jedisPool.getResource();
		String value = jedis.get("hello");
		System.out.println(value);
	} catch (Exception e){
		System.out.println(e);
		return ;
	} finally {
		if(jedis != null) {
			jedis.close();
		}
	}
}
}

部分连接池参数：
GenericObjectPoolConfig poolConfig = new GenericObjectPoolConfig();
// 设置最大连接数为默认值的5倍
poolConfig.setMaxTotal(GenericObjectPoolConfig.DEFAULT_MAX_TOTAL * 5);
// 设置最大空闲连接数为默认值的3倍
poolConfig.setMaxIdle(GenericObjectPoolConfig.DEFAULT_MAX_IDLE * 3);
// 设置最小空闲连接数为默认值的2倍
poolConfig.setMinIdle(GenericObjectPoolConfig.DEFAULT_MIN_IDLE * 2);
// 设置开启jmx功能
poolConfig.setJmxEnabled(true);
// 设置连接池没有连接后客户端的最大等待时间(单位为毫秒)
poolConfig.setMaxWaitMillis(3000);

关于jedis中实现pipeline的代码：
package Test;
import java.util.*;
import redis.clients.jedis.*;

public class testForJedisPipline {
	public void mdel (List<String> keys,Jedis jedis) {
		Pipeline pipeline1 = jedis.pipelined();
		for (String key : keys) {
			pipeline1.del(key);
		}
		//批量执行以上删除步骤
		pipeline1.sync();
		Pipeline pipeline2 = jedis.pipelined();
		pipeline2.set("hello", "shanghai");
		pipeline2.incr("counter");
		//批量执行以上步骤，将结果反馈给rsList列表
		List<Object> rsList = pipeline2.syncAndReturnAll();
		for (Object rs : rsList) {
			System.out.println(rs);
		}
	}
}

关于Jedis的总结
Jedis的使用还是比较简单的， 重点注意以下几点即可：
1） Jedis操作放在try catch finally里更加合理。
2） 区分直连和连接池两种实现方式优缺点。
3） jedis.close（ ） 方法的两种实现方式。
4） Jedis依赖了common-pool， 有关common-pool的参数需要根据不同的使用场景， 各不相同， 需要具体问题具体分析。
5） 如果key和value涉及了字节数组， 需要自己选择适合的序列化方法。


redis-py for python:
基本功能：
import redis
client = redis.StrictRedis(host='127.0.0.1', port=6379)
key = "hello"
setResult = client.set(key, "python-redis")
print setResult
value = client.get(key)
print "key:" + key + ", value:" + value

redis-py
#1.string
#输出结果： True
client.set("hello","world")
#输出结果： world
client.get("hello")
#输出结果： 1
client.incr("counter")
#2.hash
client.hset("myhash","f1","v1")
client.hset("myhash","f2","v2")
#输出结果： {'f1': 'v1', 'f2': 'v2'}
client.hgetall("myhash")
#3.list
client.rpush("mylist","1")
client.rpush("mylist","2")
client.rpush("mylist","3")
#输出结果： ['1', '2', '3']
client.lrange("mylist", 0, -1)
#4.set
client.sadd("myset","a")
client.sadd("myset","b")
client.sadd("myset","a")
#输出结果： set(['a', 'b'])
client.smembers("myset")
#5.zset
client.zadd("myzset","99","tom")
client.zadd("myzset","66","peter")
client.zadd("myzset","33","james")
#输出结果： [('james', 33.0), ('peter', 66.0), ('tom', 99.0)]
client.zrange("myzset", 0, -1, withscores=True)

redis-py中使用pipeline：
def redisPipeline(client):
     '''此处的transaction参数指定为不支持事务'''
     pipeline = client.pipeline(transaction=False)
     pipeline.set("name","vagrant")
     pipeline.sadd("myset","a")
     pipeline.sadd("myset","b")
     return pipeline.execute();



客户端管理：
client list命令能列出与Redis服务端相连的所有客户端连接信息
id=24 addr=192.168.146.1:51083 fd=6 name= age=5499 idle=2707 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=0 obl=0 oll=0 omem=0 events=r cmd=sadd
id=25 addr=127.0.0.1:41563 fd=7 name= age=2448 idle=0 flags=N db=0 sub=0 psub=0 multi=-1 qbuf=0 qbuf-free=32768 obl=0 oll=0 omem=0 events=r cmd=client
关于以上输出中的qbuf和qbuf-free，以单个连接为单位，体现输入缓存使用情况
info clients
...
client_biggest_input_buf:2097152
...
命令输出中的这行体现输入缓存占用最多的值
输入缓存无参数配置，redis中硬编码为1G/单个连接，同时不受maxmemory参数的限制

关于以上输出的obl、oll和omen，体现单个连接的反馈结果占用缓存情况
info clients
# Clients
...
client_biggest_input_buf:2097152
blocked_clients:0
以上输出中
blocked_clients： 正在执行阻塞命令（ 例如blpop、 brpop、brpoplpush） 的客户端个数。

另外，输出缓存可以通过以下方式查询：
config get client-output*
输出的规则如下：
client-output-buffer-limit <class> <hard limit> <soft limit> <soft seconds>
例如：
normal 0 0 0 slave 268435456 67108864 60 pubsub 33554432 8388608 60

可以通过以下命令查询redis最大连接数：
config get maxclients

以下命令设置客户端idle超时限制：
config get timeout
timeout=0，即关闭超时限制

flag=N说明连接的客户端是一般客户端，S表示slave客户端，O表示当前客户端执行monitor命令

关于client list其他输出说明，参见：
https://redis.io/commands/client-list

client setname test_client
为当前客户端连接设置名字

client getname
查询当前客户端连接名字

client kill ip:port
杀死指定ip:port的客户端连接

client pause timeout(毫秒)
设置客户端阻塞时间

monitor
能够实时监控所有客户端正在执行的命令
注意！，由于monitor监控全局操作，可能导致执行monitor的客户端输出缓存暴涨，影响系统整体性能

除了info clients外，
info stats
total_connections_received:80
...
rejected_connections:0
total_connections_received： Redis自启动以来处理的客户端连接数总数。
rejected_connections： Redis自启动以来拒绝的客户端连接数， 需要重点监控



redis 持久化

rdb，redis内存数据的快照
手动触发
save：
手动触发持久化过程，会阻塞所以有前台会话直到持久化过程结束，基本废弃

bgsave：
执行fork操作，创建子进程，rdb的持久化操作有子进程完成。阻塞一般发生在fork阶段，很短

自动触发
config文件中的配置
save m n
意为m秒内，数据集存在n次修改，自动触发bgsave

主从节点间执行全量初始化复制时，主节点自动执行bgsave，并将数据发送至从节点


rdb文件：
dir参数指定文件保存路径
dbfilename参数指定文件名
可以通过执行config set dir{newDir}和config set dbfilename{newFileName}运行期动态执行，下次执行rdb时，配置生效

rdbcompression参数，静态
或者
config set rdbcompression{yes|no}，动态
设置rdb文件是否压缩，默认开启

校验rdb文件
redis-check-rdb /redis/dump.rdb 

aof，append only file，以日志的形式记录写命令，从而达到数据恢复的作用
appendonly参数，静态
或者
config set appendonly {yes|no}，动态
设置aof模式

dir参数设置aof文件保存路径
appendfilename参数设置文件名
config命令无法设置appendfilename

aof文件flush策略
appendfsync控制aof缓冲区同步文件的策略，有以下三种参数：
always，每次写入aof缓冲区，同步调用fsync刷入aof文件
everysec，写入aof缓冲区后，调用write操作，fsync操作由其他进程每一秒完成一次
no，write操作写入文件系统缓存后，不做fsync同步，由OS决定实施fync操作

aof的触发条件：
手动
bgrewriteaof命令
自动
auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数
自动触发时机：
aof_current_size>auto-aof-rewrite-minsize&&（aof_current_size-aof_base_size）/aof_base_size>=auto-aof-rewritepercentage
这里的aof_current_size和aof_base_size可以通过info Persistence查询

